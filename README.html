<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h1 id="processing-scripts-for-ao-fdml-functional-oct-data-sets">Processing scripts for AO FDML functional OCT data sets</h1>
<h2 id="libraries-and-organization-of-data-and-scripts">Libraries and organization of data and scripts</h2>
<h3 id="prerequisite-libraries">Prerequisite libraries</h3>
<p>You must have the standard Python scientific stack (python 2.7, numpy, scipy, and matplotlib). The easiest way to do this is to install <a href="https://www.anaconda.com/download/">Anaconda</a>.</p>
<p>You must also have a directory for other Python libraries (e.g. <code>C:\code</code> or <code>~/code/</code>) and add this directory to your PYTHONPATH system environment variable. Then put (via git clone or http download) following libraries into that directory:</p>
<ol style="list-style-type: decimal">
<li><p>https://github.com/rjonnal/cuttlefish</p></li>
<li><p>https://github.com/rjonnal/fig2gif</p></li>
</ol>
<h3 id="organization-of-data-and-scripts">Organization of data and scripts</h3>
<p>These scripts are extremely fragile w/r/t data organization, and misplacement of data can result in untraceable bugs and data deletion.</p>
<p>All organization is relative to a data root folder whose location and name is not important. Here we refer to that location as <code>DATA_ROOT</code>. It may be, e.g., <code>C:\Data\</code> or <code>~/Data</code>.</p>
<ol style="list-style-type: decimal">
<li><p>Clone or download this repository into <code>DATA_ROOT</code>, which will create <code>DATA_ROOT/processing_ao_fdml_oct</code>. That will contain master copies of the scripts. Those copies should only be edited if the intention is to merge changes with the trunk.</p></li>
<li><p>Copy the contents of <code>DATA_ROOT/processing_ao_fdml_oct</code> up one level into <code>DATA_ROOT</code>.</p></li>
<li><p>Individual data sets should be located in <code>DATA_ROOT</code> in subfolder. We'll call this subfolder <code>DATA_ROOT/DATA_SET</code>, e.g. <code>C:/Data/2018.06.01_00.00.00_my_special_dataset</code>.</p></li>
<li><p>The dataset subfolder must have a subfolder called <code>mat</code> in it, e.g. <code>DATA_ROOT/DATA_SET/mat</code>. This is where the complex B-scan files are. These should be called <code>AMP_L_00001.mat</code> ... <code>AMP_L_NNNNN.mat</code>, ordered by order of acquisition.</p></li>
</ol>
<h2 id="running-the-scripts">Running the scripts</h2>
<h3 id="preprocessing">Preprocessing</h3>
<p>Preprocessing consists of loading B-scans from .mat files, determining the fast (resonant) and slow (galvo) turnaround points, cropping the resonant-scanner-distorted portions out of the images, reordering A-scans into their spatial order (as opposed to temporal order) to correct for B-scans' resonant and galvo directions.</p>
<h4 id="important-parameters">Important parameters:</h4>
<ol style="list-style-type: decimal">
<li><p><code>scan_fraction</code>: fraction of B-scans used to compute the bulk en face projection which is used to determine turnarounds; smaller is faster and larger is more accurate/robust.</p></li>
<li><p><code>linear_left_x_start</code> and <code>linear_left_x_end</code>: the starting and ending pixels of the linear region of the forward resonant scanner sampling. Empirically, this should be between 45% and 63% of the scan time (e.g. 70 - 100 pixels for 160 pixel scans).</p></li>
</ol>
<h4 id="running-the-script">Running the script:</h4>
<ol style="list-style-type: decimal">
<li><p>In a shell navigate to <code>DATA_ROOT</code> with, e.g., <code>cd c:\Data</code></p></li>
<li><p>Invoke the script with one parameter, the name of the dataset, e.g.: <code>python ao_fdml_foct_step_0_preprocessing.py 2018.06.01_00.00.00_my_special_dataset</code></p></li>
</ol>
<p>This will take considerable time to run. Multiple datasets may be run simultaneously on a multi-core machine by creating multiple shells (command prompts) and performing steps 1 and 2 above for each dataset.</p>
<h4 id="output-of-the-script">Output of the script</h4>
<ol style="list-style-type: decimal">
<li><p>Spatially-ordered volumes, located in <code>DATA_SET/volumes/NNNN/processed_data.npy</code>. These are as described above. Each of these is a <code>2 x n_slow x n_depth x n_fast</code> array where the first dimension is size 2, corresponding to each of the forward and backward resonant scans.</p></li>
<li><p>Spatially-ordered timestamps, located in <code>DATA_SET/volumes/NNNN/data_time.npy</code>. These are <code>2 x n_slow x n_fast</code> arrays containing the acquisition time for each A-line in <code>processed_data.npy</code>.</p></li>
<li><p>Output of model-based segmentation, located in <code>DATA_SET/volumes/NNNN/model/</code>.</p></li>
<li><p>Flattening offsets, located in <code>DATA_SET/volumes/NNNN/flat_offsets.npy</code>, a <code>2 x n_slow x n_fast</code> array containing axial offsets which can be used to flatten the volumes.</p></li>
<li><p>En face projections of various parts of the volume, located in <code>DATA_SET/volumes/NNNN/projections/</code>.</p></li>
</ol>
</body>
</html>
